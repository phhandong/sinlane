<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SinLane</title>
    <style>
      .hero {
        display: flex;
        justify-content: center;
        align-items: center;
      }
      .carousel .item {
        display: flex;
        flex-direction: column;
        align-items: center;
        text-align: center;
      }
      .carousel .item img {
        display: block;
        margin: 0 auto;
      }
      .carousel .item h2 {
        margin-top: 10px;
      }
    </style>

    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Academic Project Page</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" /> -->
    <link
      rel="icon"
      type="image/png"
      href="static/images/heu.png"
      sizes="128x128"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                SinLane: Siamese Visual Transformer following Pyramid Feature
                Integration for Lane Detection
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="FIRST AUTHOR PERSONAL LINK" target="_blank"
                    >Zinan Lv</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank"
                    >Dong Han</a
                  ><sup>2†</sup>,</span
                >
                <span class="author-block">
                  <a href="THIRD AUTHOR PERSONAL LINK" target="_blank"
                    >Wenzhe Wang</a
                  ><sup>2††</sup>,</span
                >
                <span class="author-block">
                  <a href="THIRD AUTHOR PERSONAL LINK" target="_blank"
                    >Danny Chen</a
                  ><sup>3</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  ><sup>1</sup>Shanghai Jiao Tong University,
                  <sup>2</sup>Zhejiang University, <br /><sup>3</sup>University
                  of Notre Dame, <br />
                  ECAI 2024</span
                >
                <span class="eql-cntrb"
                  ><small><br /><sup>†</sup>Corresponding Author</small></span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <!-- <span class="link-block">
                    <a
                      href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span> -->

                  <!-- Supplementary PDF link
                  <span class="link-block">
                    <a
                      href="static/pdfs/supplementary_material.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="https://github.com/YOUR REPO HERE"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <!-- <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/<ARXIV PAPER ID>"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span> -->
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <div class="item">
            <img
              src="static\images\teaser_pic.png"
              alt="MY ALT TEXT"
              style="max-width: 100%"
            />
            <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/banner_video.mp4" type="video/mp4" />
          </video> -->
            <h2 style="font-size: 18px" class="subtitle has-text-centered">
              <b>Overall architecture</b> of our proposed SinLane network. The
              backbone first extracts multi-scale features from the input image.
              PFI is then applied to fully integrate global semantic information
              and local finer-scale features. Subsequently, Siamese Visual
              Transformer (Encoder and Decoder) generates lane sequences.
              Specifically, <span> \( e_0 \) </span> is the initial lane
              sequence, and <span> \( e_1 \) </span>, <span> \( e_2 \) </span>,
              and <span> \( e_3 \) </span> denote refined lane sequences
              optimized by different scales of feature maps from PFI.
            </h2>
          </div>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Lane detection is an important yet challenging task in
                autonomous driving systems. Based on the development of the
                Visual Transformer, early Transformer-based lane detection
                studies have achieved promising results in some scenarios.
                However, for complex road conditions such as uneven illumination
                intensity and heavy traffic, the performance of these methods
                remains limited and may even be worse than that of
                contemporaneous CNN-based methods. In this paper, we propose a
                novel Transformer-based end-to-end network, called SinLane, that
                attains the attention weights focusing on the sparse yet
                meaningful locations and improves the accuracy of lane detection
                in complex environments. SinLane is composed of a novel Siamese
                Visual Transformer structure and a novel Feature Pyramid Network
                (FPN) structure called Pyramid Feature Integration (PFI). We
                utilize the proposed PFI to better integrate global semantics
                and finer-scale features and to promote the optimization of the
                Transformer. Moreover, the designed Siamese Visual Transformer
                is combined with multiple levels of the PFI and is employed to
                refine the multi-scale lane line features output from the PFI.
                Extensive experiments on three benchmark datasets of lane
                detection demonstrate that our SinLane achieves state-of-the-art
                results with high accuracy and efficiency. Specifically, our
                SinLane improves the accuracy by over <b>3%</b> compared to the
                current best-performing Transformer-based method for lane
                detection on CULane. Our code has be released.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Image carousel -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item" style="text-align: center">
              <img
                src="static/images/siamese.png"
                alt="MY ALT TEXT"
                style="max-width: 55%"
              />
              <h2 class="subtitle has-text-centered">
                The main structure of the Siamese Visual Transformer.
              </h2>
            </div>
            <div class="item" style="text-align: center">
              <img
                src="static/images/PFI.png"
                alt="MY ALT TEXT"
                style="max-width: 80%"
              />
              <h2 class="subtitle has-text-centered">
                The architecture of our proposed PFI. The inputs of PFI are
                different scales of feature maps generated by the backbone.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End image carousel -->

    <!-- Video carousel -->
    <!-- <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Another Carousel</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-video1">
              <video
                poster=""
                id="video1"
                autoplay
                controls
                muted
                loop
                height="100%"
              >
                <source src="static/videos/carousel1.mp4" type="video/mp4" />
              </video>
            </div>
            <div class="item item-video2">
              <video
                poster=""
                id="video2"
                autoplay
                controls
                muted
                loop
                height="100%"
              >
                <source src="static/videos/carousel2.mp4" type="video/mp4" />
              </video>
            </div>
            <div class="item item-video3">
              <video
                poster=""
                id="video3"
                autoplay
                controls
                muted
                loop
                height="100%"
              >
                \
                <source src="static/videos/carousel3.mp4" type="video/mp4" />
              </video>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End video carousel -->

    <!-- Attention Maps -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <!-- Paper video. -->
          <h2 class="title">Attention Maps</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="item">
                <!-- Your image here -->
                <img
                  src="static\images\attention_map.png"
                  alt="MY ALT TEXT"
                  style="max-width: 65%"
                />
                <h2 class="subtitle has-text-centered">
                  Attention map examples of LSTR and our proposed SinLane. The
                  two models are both trained with the same number of epochs.
                  The attention weights of LSTR concentrate on the middle area
                  of the lane lines. On the contrary, the attention weights of
                  our method are evenly distributed from top to bottom on each
                  line on the road.
                </h2>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Quality results -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Quality Results</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="item">
                <!-- Your image here -->
                <img
                  src="static\images\visualization.png"
                  alt="MY ALT TEXT"
                  style="max-width: 100%"
                />
                <h2 class="subtitle has-text-centered">
                  Visualization results of ground truth (GT), LSTR, CLRNet, and
                  our SinLane method on the benchmark dataset CULane. The
                  results are generated using the same backbone ResNet18.
                </h2>
                <!-- <img
                  src="static\images\hard_cases.png"
                  alt="MY ALT TEXT"
                  style="max-width: 100%"
                />
                <h2 class="subtitle has-text-centered">
                  Failure cases of LSTR, CLRNet, and our proposed method SinLane
                  on CULane. The results are generated with the same backbone
                  ResNet18.
                </h2> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--End Quality results -->

    <!-- Results -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Quantitative Results</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="item">
                <!-- Your image here -->
                <img
                  src="static\images\result_tab_culane.png"
                  alt="MY ALT TEXT"
                  style="max-width: 100%"
                />
                <h2 class="subtitle has-text-centered">
                  Comparison results of recent methods and our method on the
                  CULane dataset. In order to compare the computation speeds in
                  the same environment, we remeasure FPS on the same machine
                  with an RTX3090 GPU using open-source code (if code is
                  available).
                </h2>
                <img
                  src="static\images\result_tab_tusimple.png"
                  alt="MY ALT TEXT"
                  style="max-width: 50%"
                />
                <h2 class="subtitle has-text-centered">
                  Comparison results on the Tusimple dataset.
                </h2>
                <img
                  src="static\images\result_tab_llamas.png"
                  alt="MY ALT TEXT"
                  style="max-width: 50%"
                />
                <h2 class="subtitle has-text-centered">
                  Comparison results on the LLAMAS dataset.
                </h2>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--End Results -->

    <!-- Cu video -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <!-- Paper video. -->
          <h2 class="title is-3">
            Video Results on CULane & Tusimple & LLAMAS dataset (TODO)
          </h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="publication-video">
                <!-- Youtube embed code here -->
                <iframe
                  src="https://www.youtube.com/embed/JkaxUblCGz0"
                  frameborder="0"
                  allow="autoplay; encrypted-media"
                  allowfullscreen
                ></iframe>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End youtube video -->

    <!-- Paper poster -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Poster (TODO)</h2>

          <!-- <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe> -->
        </div>
      </div>
    </section>
    <!--End paper poster -->

    <!-- Supplement material -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Supplement Material</h2>
          <iframe
            src="static\pdfs\Sup_ECAI_24__SinLane__Siamese_Visual_Transformer_following_Pyramid_Feature_Integration_for_Lane_Detection.pdf"
            width="100%"
            height="550"
          >
          </iframe>
        </div>
      </div>
    </section>
    <!--End Supplement material -->

    <!--BibTex citation -->
    <!-- <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>BibTex Code Here</code></pre>
      </div>
    </section> -->
    <!--End BibTex citation -->

    <!-- <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page. You are free to borrow the of this website, we
                just ask that you link back to this page in the footer. <br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer> -->

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
